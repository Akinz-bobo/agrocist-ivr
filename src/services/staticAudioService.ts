import logger from "../utils/logger";
import cloudinaryService from "./cloudinaryService";
import localAudioService from "./localAudioService";
import config from "../config";
import { stripQueryParams } from "../utils/urlUtils";
import Spitch from "spitch";

export interface StaticAudioTexts {
  welcome: string;
  processing: string;
  analysisWait: string;
  error: string;
  goodbye: string;
  noRecording: string;
  wait: string;
  directRecording: string;
  followUpRecording: string;
  postAIMenu: string;
  noInputMessage: string;
  transfer: string;
  languageTimeout: string;
}

class StaticAudioService {
  private client: Spitch;
  // private staticTexts: Record<string, StaticAudioTexts> = {
  //   en: {
  //     welcome:
  //       "Welcome to Agrocist, your trusted livestock farming partner. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo.",
  //     processing:
  //       "Thank you for your question. Agrocist is analyzing your concern.",
  //     analysisWait:
  //       "Please wait while we analyze your concern. This may take a few moments.",
  //     error:
  //       "I'm sorry, I didn't understand that. Let me take you back to the main menu.",
  //     goodbye: "Thank you for using Agrocist. Have a great day!",
  //     noRecording:
  //       "I didn't hear your recording. Please try again and speak after the beep.",
  //     wait: "Just a moment, processing your request.",
  //     directRecording:
  //       "You have selected English. Please describe your livestock concern. Speak clearly after the beep and press hash when done.",
  //     followUpRecording: "What else can I help you with?",
  //     postAIMenu: "Press 1 for another question or press 0 to end the call.",
  //     noInputMessage:
  //       "We did not receive your selection. Let me repeat the options.",
  //     transfer:
  //       "Please hold while I connect you to one of our veterinary experts.",
  //     languageTimeout:
  //       "We did not receive your response. Let me repeat the options. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo.",
  //   },
  //   yo: {
  //     welcome:
  //       "·∫∏ k√°√†b·ªçÃÄ s√≠ Agrocist, al√°b√°·π£ep·ªçÃÄ √≤we ·∫πranko t√≠ ·∫π l√® gb·∫πÃÅk·∫πÃÄl√©. ·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n G·∫πÃÄ·∫πÃÅs√¨, m√©j√¨ f√∫n Yor√πb√°, m·∫πÃÅta f√∫n Hausa, t√†b√≠ m·∫πÃÅrin f√∫n Igbo.",
  //     processing: "A d√∫p·∫πÃÅ f√∫n √¨b√©√®r√® y√≠n. Agrocist ≈Ñ ·π£e √¨t√∫pal·∫πÃÄ √¨·π£√≤ro y√≠n.",
  //     analysisWait:
  //       "·∫∏ d√∫r√≥ d√≠·∫πÃÄ k√≠ a ·π£e √¨t√∫pal·∫πÃÄ √¨·π£√≤ro y√≠n. √ày√≠ l√® gba √†k√≥k√≤ d√≠·∫πÃÄ.",
  //     error:
  //       "M√° b√≠n√∫, k√≤ y√© mi ohun t√≠ ·∫π s·ªç. ·∫∏ j·∫πÃÅ k√≠ n gb√© y√≠n pad√† s√≠ √†t√≤j·ªç √†k·ªçÃÅk·ªçÃÅ.",
  //     goodbye: "A d√∫p·∫πÃÅ f√∫n lilo Agrocist. ·∫∏ n√≠ ·ªçj·ªçÃÅ t√≠ √≥ d√°ra!",
  //     noRecording:
  //       "Mi √≤ gb·ªçÃÅ √¨gb√≥h√πn y√≠n. ·∫∏ j·ªçÃÄw·ªçÃÅ gb√¨y√†nj√∫ l·∫πÃÅ·∫πÃÄkan si, k√≠ ·∫π s√¨ s·ªçÃÄr·ªçÃÄ l·∫πÃÅy√¨n √¨r√≥ √†l√°m·ªçÃÅ.",
  //     wait: "·∫∏ d√∫r√≥ d√≠·∫πÃÄ, a ≈Ñ ·π£e √¨b√©√®r√® y√≠n.",
  //     directRecording:
  //       "·∫∏ ti yan √àd√® Yor√πb√°. ·∫∏ s·ªç √¨·π£√≤ro ·∫πranko y√≠n kedere l·∫πÃÅy√¨n √¨r√≥ √†l√°m·ªçÃÅ (beep), k√≠ ·∫π s√¨ t·∫πÃÅ hash n√≠gb√† t√≠ ·∫π b√° par√≠.",
  //     followUpRecording: "K√≠ni m√¨√≠r√†n t√≠ mo l√® ·π£e f√∫n y√≠n?",
  //     postAIMenu:
  //       "·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n √¨b√©√®r√® m√¨√≠r√†n t√†b√≠ ·∫π t·∫πÃÅ ·ªçÃÄf√† l√°ti par√≠ √¨p√® n√°√†.",
  //     noInputMessage: "A k√≤ gb·ªçÃÅ √†·π£√†y√†n y√≠n. ·∫∏ j·∫πÃÅ k√≠ n t√∫n √†w·ªçn √†·π£√†y√†n n√°√† s·ªç.",
  //     transfer:
  //       "·∫∏ d√∫r√≥ s√≠b·∫πÃÄ k√≠ n so y√≠n m·ªçÃÅ ·ªçÃÄkan l√°ra √†w·ªçn am·ªçÃÄr√†n on√≠w√≤s√†n ·∫πranko wa.",
  //     languageTimeout:
  //       "A k√≤ gb·ªçÃÅ √¨d√°h√πn y√≠n. ·∫∏ j·∫πÃÅ k√≠ n t√∫n √†w·ªçn √†·π£√†y√†n n√°√† s·ªç. ·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n G·∫πÃÄ·∫πÃÅs√¨, m√©j√¨ f√∫n Yor√πb√°, m·∫πÃÅta f√∫n Hausa, t√†b√≠ m·∫πÃÅrin f√∫n Igbo.",
  //   },
  //   ha: {
  //     welcome:
  //       "Maraba da zuwa Agrocist, abokin gona na kiwo da za ku iya dogara da shi. Danna 1 don Turanci, 2 don Yoruba, 3 don Hausa, ko 4 don Igbo.",
  //     processing: "Na gode da tambayar ku. Agrocist yana nazarin damuwar ku.",
  //     analysisWait:
  //       "Don Allah ku jira yayin da muke nazarin damuwar ku. Wannan na iya …óaukar …óan lokaci.",
  //     error:
  //       "Yi hakuri, ban fahimci hakan ba. Bari in mayar da ku zuwa babban menu.",
  //     goodbye: "Na gode da amfani da Agrocist. Ku yi kyakkyawan rana!",
  //     noRecording:
  //       "Ban ji rikodin ku ba. Don Allah ku sake gwadawa kuma ku yi magana bayan sautin.",
  //     wait: "Don Allah ku …óan jira, muna aiwatar da bu∆ôatarku.",
  //     directRecording:
  //       "Kun za…ìi Hausa. Don Allah ku bayyana matsalar dabbobinku. Ku yi magana a bayyane bayan sautin (beep), sannan ku danna hash idan kun gama.",
  //     followUpRecording: "Me kuma zan iya taimaka muku da shi?",
  //     postAIMenu: "Danna 1 don wata tambaya ko danna 0 don kammala kiran.",
  //     noInputMessage: "Ba mu kar…ìi za…ìin ku ba. Bari in sake maimaita za…ìukan.",
  //     transfer:
  //       "Don Allah ku jira yayin da nake ha…óa ku da …óaya daga cikin ∆ôwararrun likitocin dabbobinmu.",
  //     languageTimeout:
  //       "Ba mu kar…ìi amsar ku ba. Bari in sake maimaita za…ìukan. Danna 1 don Turanci, 2 don Yoruba, 3 don Hausa, ko 4 don Igbo.",
  //   },
  //   ig: {
  //     welcome:
  //       "Nn·ªç·ªç na Agrocist, onye enyi g·ªã n'·ªçr·ª• an·ª•man·ª• ·ªã nwere ike ·ªãdabere na ya. P·ªãa 1 maka Bekee, 2 maka Yoruba, 3 maka Hausa, ma ·ªç b·ª• 4 maka Igbo.",
  //     processing: "Daal·ª• maka aj·ª•j·ª• g·ªã. Agrocist na-enyocha nsogbu g·ªã.",
  //     analysisWait:
  //       "Biko chere ka any·ªã nyochaa nsogbu g·ªã. Nke a nwere ike were obere oge.",
  //     error:
  //       "Ewela iwe, agh·ªçtagh·ªã m ihe ·ªã kwuru. Ka m laghachi g·ªã na menu izizi.",
  //     goodbye: "Daal·ª• maka iji Agrocist. Nwee ·ª•b·ªçch·ªã ·ªçma!",
  //     noRecording:
  //       "An·ª•gh·ªã m ndek·ªç g·ªã. Biko gbal·ªãa ·ªçz·ªç ma kwuo okwu mgbe ·ª•da ah·ª• gas·ªãr·ªã.",
  //     wait: "Chere ntak·ªãr·ªã, any·ªã na-edozi ihe ·ªã ch·ªçr·ªç.",
  //     directRecording:
  //       "·ªäh·ªçr·ªçla Igbo. Biko k·ªçwaa nsogbu an·ª•man·ª• g·ªã. Kwuo okwu n'·ª•z·ªç doro anya mgbe ·ª•da ah·ª• (beep) gas·ªãr·ªã, wee p·ªãa hash mgbe ·ªã mechara.",
  //     followUpRecording: "G·ªãn·ªã ·ªçz·ªç ka m nwere ike inyere g·ªã aka?",
  //     postAIMenu: "P·ªãa 1 maka aj·ª•j·ª• ·ªçz·ªç ma ·ªç b·ª• p·ªãa 0 iji kw·ª•s·ªã oku a.",
  //     noInputMessage: "Any·ªã anatabegh·ªã nh·ªçr·ªç g·ªã. Ka m kwughachi nh·ªçr·ªç nd·ªã ah·ª•.",
  //     transfer:
  //       "Biko chere ka m jik·ªç·ªç g·ªã na otu n'ime nd·ªã ·ªçkachamara veterinary any·ªã.",
  //     languageTimeout:
  //       "Any·ªã anatabegh·ªã az·ªãza g·ªã. Ka m kwughachi nh·ªçr·ªç nd·ªã ah·ª•. P·ªãa 1 maka Bekee, 2 maka Yoruba, 3 maka Hausa, ma ·ªç b·ª• 4 maka Igbo.",
  //   },
  // };
  staticTexts: Record<string, any> = {
    en: {
      welcome:
        "Welcome to Agrocist, your trusted livestock farming partner. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo.",
      processing:
        "Thank you for your question. Agrocist is analyzing your concern.",
      analysisWait:
        "Please wait while we analyze your concern. This may take a few moments.",
      error:
        "I'm sorry, I didn‚Äôt understand that. Let me take you back to the main menu.",
      goodbye: "Thank you for using Agrocist. Have a great day!",
      noRecording:
        "I didn‚Äôt hear your recording. Please try again and speak after the beep.",
      wait: "Just a moment, processing your request.",
      directRecording:
        "You have selected English. Please describe your livestock concern. Speak clearly after the beep and press hash when done.",
      followUpRecording: "What else can I help you with?",
      postAIMenu: "Press 1 for another question, or press 0 to end the call.",
      noInputMessage:
        "We did not receive your selection. Let me repeat the options.",
      transfer:
        "Please hold while I connect you to one of our veterinary experts.",
      languageTimeout:
        "We did not receive your response. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo.",
    },

    yo: {
      processing: "O ·π£eun f√∫n √¨b√©√®r√® y√≠n. Agrocist ≈Ñ ·π£e √¨t√∫pal·∫πÃÄ √¨b√©√®r√® y√≠n.",
      analysisWait:
        "·∫∏ j·ªçÃÄ·ªçÃÅ, ·∫π d√∫r√≥ d√≠·∫πÃÄ k√≠ a l√® ·π£e √¨t√∫pal·∫πÃÄ √¨b√©√®r√® y√≠n. √ì l√® gba √¨s·∫πÃÅj√∫ d√≠·∫πÃÄ.",
      error:
        "·∫∏ m√° b√≠n√∫, ohun t√≠ ·∫π s·ªç k√≤ ye m√≠. ·∫∏ j·∫πÃÅ k√≠ n gbe y√≠n pad√† s√≠ ipele √†k·ªçÃÅk·ªçÃÅ.",
      goodbye: "O ·π£eun f√∫n l√≠lo Agrocist. ·∫∏ n√≠ ·ªçj·ªçÃÅ √†l√†√°f√≠√†!",
      noRecording:
        "Mi √≤ gb·ªçÃÅ ohun t√≠ ·∫π w√≠. ·∫∏ j·ªçÃÄ·ªçÃÅ, k√≠ ·∫π gb√¨y√†nj√∫ l·∫πÃÅ·∫πÃÄkansi l·∫πÃÅy√¨n t√≠ ·∫π b√° gb·ªçÃÅ agogo n√°√†.",

      wait: "·∫∏ j·ªçÃÄ·ªçÃÅ, ·∫π d√∫r√≥ d√≠·∫πÃÄ, a ≈Ñ ·π£e √¨m√∫l√≤l√πf·∫πÃÅ √¨b√©√®r√® y√≠n.",
      directRecording:
        "·∫∏ ti yan √®d√® Yor√πb√°. ·∫∏ ·π£√†p√®j√∫we √¨b√©√®r√® ·∫πran-·ªçÃÄs√¨n y√≠n. ·∫∏ s·ªç kedere l·∫πÃÅy√¨n t√≠ ·∫π gb·ªçÃÅ agogo n√°√†. K√≠ ·∫π s√¨ t·∫π haasi n√≠gb√† t√≠ ·∫π b√° par√≠.",
      followUpRecording: "K√≠ ni m√≠√¨ t√≠ ·∫π f·∫πÃÅ k√≠ n ran y√≠n l·ªçÃÅw·ªçÃÅ?",
      postAIMenu: "T·∫π ookan f√∫n √¨b√©√®r√® m√≠√¨, t√†b√≠ t·∫π oodo l√°ti par√≠ √¨p√®.",
      noInputMessage:
        "A k√≤ gba y√≠yan kankan. ·∫∏ j·∫πÃÅ k√≠ n t√∫n √†w·ªçn √†·π£√†y√†n n√°√† s·ªç.",
      transfer: "·∫∏ j·ªçÃÄ·ªçÃÅ, ·∫π d√∫r√≥ d√≠·∫πÃÄ k√≠ n b√° y√≠n so p·ªçÃÄ m·ªçÃÅ am√≤fin ·∫πranko wa.",
      languageTimeout:
        "·∫∏ √≤ t·∫πÃÅ nkankan, t·∫πÃÅ ookan f√∫n G·∫πÃÄ·∫πÃÅs√¨, eeji f√∫n Yor√πb√°, eeta f√∫n Hausa, t√†b√≠ eerin f√∫n √ågb√≤.",
    },

    ha: {
      processing: "Mun gode da tambayarka. Agrocist yana nazarin tambayar ka.",
      analysisWait:
        "Da fatan za ka jira yayin da muke nazarin tambayar ka. Wannan zai iya …óaukar …óan lokaci ka…óan.",
      error:
        "Yi ha∆ôuri, ban fahimci abin da ka fa…óa ba. Zan mayar da kai zuwa babban menu.",
      goodbye: "Mun gode da amfani da Agrocist. Yi rana mai kyau!",
      noRecording:
        "Ban ji abin da kuka fa…óa ba. Da fatan za ku sake gwadawa bayan karar beep.",

      wait: "Da fatan ka jira, muna sarrafa bu∆ôatarka.",
      directRecording:
        "Ka za…ìi Hausa. Don Allah ka bayyana tambayar da ta shafi dabbobinka. Ka yi magana a sarari bayan beep sannan ka danna hash idan ka gama.",
      followUpRecording: "Me zan taimaka maka da shi kuma?",
      postAIMenu: "Latsa daya don wani tambaya, ko sifili don rufe kiran.",
      noInputMessage: "Ba mu samu zabinka ba. Zan maimaita za…ìu…ì…ìukan.",
      transfer:
        "Da fatan ka jira yayin da nake ha…óa ka da kwararren likitan dabbobi.",
      languageTimeout:
        "Ba ku danna komai ba, latsa daya don Turanci, biyu don Yoruba, uku don Hausa, ko hudu don Igbo.",
    },

    ig: {
      processing: "Daal·ª• maka aj·ª•j·ª• g·ªã. Agrocist na-enyocha aj·ª•j·ª• ·ªã j·ª•r·ª•.",
      analysisWait:
        "Biko chere obere ka any·ªã nyochaa aj·ª•j·ª• g·ªã. Nke a nwere ike were obere oge.",
      error:
        "Biko, echegh·ªã m ihe i kwuru nke ·ªçma. Ka m weghachite g·ªã na isi menu.",
      goodbye: "Daal·ª• maka iji Agrocist. Ka ·ª•b·ªçchi g·ªã b·ª•r·ª• nke ·ªçma!",
      noRecording:
        "An·ª•gh·ªã m ihe ·ªã kwuru. Biko gbal·ªãa ·ªçz·ªç mgbe ·ª•da beep gas·ªãr·ªã.",
      wait: "Biko chere ntak·ªãr·ªã ka any·ªã na-emek·ªç ihe i r·ªã·ªçr·ªç.",
      directRecording:
        "·ªä h·ªçr·ªçla Igbo. Biko k·ªçwaa aj·ª•j·ª• gbasara an·ª•man·ª• g·ªã. Kwuo nke ·ªçma mgbe beep gas·ªãr·ªã ma p·ªãa hash mgbe ·ªã gw·ª•chara.",
      followUpRecording: "Kedu ihe ·ªçz·ªç ka m nwere ike inyere g·ªã?",
      postAIMenu: "P·ªãa otu maka aj·ª•j·ª• ·ªçz·ªç, ma ·ªç b·ª• p·ªãa efu ka ·ªã kw·ª•s·ªã oku.",
      noInputMessage: "Any·ªã enwetagh·ªã nh·ªçr·ªç g·ªã. Ka m kwughachi nh·ªçr·ªç nd·ªã ah·ª•.",
      transfer: "Biko chere ka m jik·ªç·ªç g·ªã na ·ªçkachamara an·ª•man·ª•.",
      languageTimeout:
        "·ªä nwegh·ªã p·ªãa ihe ·ªç b·ª•la, p·ªãa otu maka Bekee, ab·ª•·ªç maka Yoruba, at·ªç maka Hausa, ma ·ªç b·ª• an·ªç maka Igbo.",
    },
  };

  private staticAudioUrls: Map<string, string> = new Map();

  constructor() {
    this.client = new Spitch({
      apiKey: config.spitch.apiKey,
    });
  }

  /**
   * Pre-generate all static audio files at startup
   */
  async preGenerateStaticAudio(): Promise<void> {
    logger.info("üéµ Starting static audio pre-generation with Spitch API...");
    const startTime = Date.now();
    let successCount = 0;
    let failedCount = 0;

    // Check Spitch API configuration
    if (!config.spitch.apiKey) {
      logger.error(
        "‚ùå Spitch API key not configured - static audio generation failed"
      );
      logger.info("üéµ Static audio pre-generation completed in 0ms");
      logger.info(
        `‚úÖ Success: 0, ‚ùå Failed: 0, Total: 0 (failed due to missing Spitch API key)`
      );
      return;
    }

    const languages: Array<"en" | "yo" | "ha" | "ig"> = [
      "en",
      "yo",
      "ha",
      "ig",
    ];

    // Build list of all files to process
    const allFiles: Array<{ language: string; key: string; text: string }> = [];

    for (const language of languages) {
      const texts = this.staticTexts[language];

      if (!texts) {
        logger.error(`‚ùå No texts found for language: ${language}`);
        continue;
      }

      // Add each file to the processing queue
      for (const [key, text] of Object.entries(texts)) {
        allFiles.push({ language, key, text: text as string });
      }
    }

    logger.info(
      `üöÄ Processing ${allFiles.length} static audio files sequentially...`
    );

    // Process files one by one to avoid overwhelming TTS API
    const results: PromiseSettledResult<void>[] = [];

    for (let i = 0; i < allFiles.length; i++) {
      const file = allFiles[i];
      if (!file) continue;

      logger.info(`üìÑ Processing file ${i + 1}/${allFiles.length}...`);

      try {
        await this.processStaticAudio(file.language, file.key, file.text);
        results.push({ status: "fulfilled", value: undefined });
      } catch (error) {
        results.push({ status: "rejected", reason: error });
      }

      // Add a delay between each file to prevent API rate limiting
      if (i + 1 < allFiles.length) {
        await new Promise((resolve) => setTimeout(resolve, 2000)); // 2 second delay between files
      }
    }

    // Count results
    results.forEach((result, index) => {
      if (result.status === "fulfilled") {
        successCount++;
      } else {
        failedCount++;
        logger.error(`‚ùå Task ${index} failed:`, result.reason);
      }
    });

    const totalTime = Date.now() - startTime;
    logger.info(`üéµ Static audio pre-generation completed in ${totalTime}ms`);
    logger.info(
      `‚úÖ Success: ${successCount}, ‚ùå Failed: ${failedCount}, Total: ${
        successCount + failedCount
      }`
    );
  }

  /**
   * Get pre-generated static audio URL
   */
  getStaticAudioUrl(
    language: "en" | "yo" | "ha" | "ig",
    textKey: keyof StaticAudioTexts
  ): string | null {
    // Special case for postAIMenu_en - use renamed file
    if (language === "en" && textKey === "postAIMenu") {
      return "https://res.cloudinary.com/dk9oamdmg/video/upload/v1/agrocist-ivr/audio/static/postAIMenu_en_new_changed.mp3";
    }

    const cacheKey = `${language}_${textKey}`;
    return this.staticAudioUrls.get(cacheKey) || null;
  }

  /**
   * Get static text for fallback
   */
  getStaticText(
    language: "en" | "yo" | "ha" | "ig",
    textKey: keyof StaticAudioTexts
  ): string {
    const languageTexts = this.staticTexts[language];
    const englishTexts = this.staticTexts.en;

    return languageTexts?.[textKey] || englishTexts?.[textKey] || "";
  }

  /**
   * Process a single static audio file (check existence + generate if needed)
   */
  private async processStaticAudio(
    language: string,
    key: string,
    text: string
  ): Promise<void> {
    const cacheKey = `${language}_${key}`;
    let finalUrl: string | null = null;

    // FASTEST PATH: Check if we already have this file URL cached in memory
    if (this.staticAudioUrls.has(cacheKey)) {
      finalUrl = this.staticAudioUrls.get(cacheKey)!;
      logger.info(`‚ö° SKIPPED: Using cached static audio URL: ${cacheKey}`);
      return;
    }

    // FAST PATH: Check if file exists locally or on Cloudinary (only if not in memory cache)
    if (localAudioService.isEnabled()) {
      // Check local storage first
      const localUrl = `/audio/static/${language}_${key}.mp3`;
      if (localAudioService.fileExists(localUrl)) {
        finalUrl = `${config.webhook.baseUrl}${localUrl}`;
        logger.info(
          `‚ôªÔ∏è SKIPPED: Using existing local static file: ${cacheKey}`
        );
      } else {
        // Generate and save using unified method
        logger.info(`üì§ Generating new static audio: ${cacheKey}`);
        finalUrl = await this.uploadStaticToCloudinary(text, language, key);
        if (finalUrl) {
          logger.info(`‚úÖ Saved new static audio: ${cacheKey}`);
        }
      }
    } else if (cloudinaryService.isEnabled()) {
      const basePublicId = cloudinaryService.generatePublicId(
        text,
        language,
        "static",
        key
      );
      const staticPublicId = `${config.cloudinary.folder}/static/${basePublicId}`;

      try {
        logger.info(
          `üîç Checking for existing file on Cloudinary: ${staticPublicId}`
        );
        const existsOnCloudinary = await cloudinaryService.fileExists(
          staticPublicId
        );

        if (existsOnCloudinary) {
          // File already exists, use the existing URL (FAST PATH)
          const existingCloudinaryUrl =
            cloudinaryService.getOptimizedUrl(staticPublicId);
          if (existingCloudinaryUrl) {
            finalUrl = stripQueryParams(existingCloudinaryUrl);
            logger.info(
              `‚ôªÔ∏è SKIPPED: Using existing static Cloudinary file: ${cacheKey} (${staticPublicId})`
            );
          }
        } else {
          // File doesn't exist, generate and upload it (SLOW PATH)
          logger.info(
            `üì§ Generating new static audio: ${cacheKey} (will upload as ${staticPublicId})`
          );
          finalUrl = await this.uploadStaticToCloudinary(text, language, key);
          if (finalUrl) {
            logger.info(
              `‚úÖ Uploaded new static audio to Cloudinary: ${cacheKey}`
            );
          }
        }
      } catch (error) {
        // If Cloudinary API is having issues, try to get URL directly first
        logger.warn(
          `Cloudinary API error for ${cacheKey}, trying direct URL:`,
          error
        );
        const directUrl = cloudinaryService.getOptimizedUrl(staticPublicId);
        if (directUrl) {
          finalUrl = stripQueryParams(directUrl);
          logger.info(
            `‚ôªÔ∏è Using direct Cloudinary URL despite API error: ${cacheKey}`
          );
        } else {
          // Last resort: generate new file
          finalUrl = await this.uploadStaticToCloudinary(text, language, key);
          if (finalUrl) {
            logger.info(
              `‚úÖ Generated static audio despite API issues: ${cacheKey}`
            );
          }
        }
      }
    } else {
      // Storage disabled, generate anyway
      finalUrl = await this.uploadStaticToCloudinary(text, language, key);
    }

    if (finalUrl) {
      this.staticAudioUrls.set(cacheKey, stripQueryParams(finalUrl));
      logger.debug(`‚úÖ Generated ${cacheKey}: ${text.substring(0, 50)}...`);
    } else {
      logger.error(
        `‚ùå Failed to generate static audio for ${cacheKey} - static file not available`
      );
    }
  }

  /**
   * Upload static audio file using unified storage method
   */
  async uploadStaticToCloudinary(
    text: string,
    language: string,
    textKey: string
  ): Promise<string | null> {
    try {
      // Use centralized static publicId generation for consistency
      const publicId = cloudinaryService.generatePublicId(
        text,
        language,
        "static",
        textKey
      );

      console.log(
        `Uploading static audio to Cloudinary with publicId: ${publicId}`
      );

      // Generate TTS audio buffer directly (don't save to disk)
      let audioBuffer = await this.generateTTSBuffer(
        text,
        language as "en" | "yo" | "ha" | "ig"
      );
      if (!audioBuffer) {
        logger.warn(
          `Failed to generate TTS buffer for static audio: ${language}_${textKey}`
        );
        return null;
      }

      // // Convert to 8kHz if ffmpeg is available
      // const { AudioProcessor } = await import("../utils/audioProcessor");
      // if (await AudioProcessor.isFFmpegAvailable()) {
      //   try {
      //     audioBuffer = await AudioProcessor.convertTo8kHz(audioBuffer);
      //     logger.info(
      //       `Converted static audio to 8kHz: ${audioBuffer.length} bytes`
      //     );
      //   } catch (error) {
      //     logger.warn(`Failed to convert static audio to 8kHz: ${error}`);
      //   }
      // }

      // Use unified upload method (handles local first, then Cloudinary)
      const cloudinaryResult = await cloudinaryService.uploadAudioBuffer(
        audioBuffer,
        {
          publicId,
          folder: `${config.cloudinary.folder}/static`,
          type: "static",
          language,
          textKey,
        }
      );

      if (cloudinaryResult) {
        logger.info(`‚úÖ Successfully saved static audio:`);
        logger.info(`   üìÑ File: ${language}_${textKey}`);
        logger.info(`   üåê URL: ${cloudinaryResult.secureUrl}`);
        return cloudinaryResult.secureUrl;
      }
    } catch (error) {
      logger.warn(
        `Failed to upload static audio to Cloudinary: ${language}_${textKey}`,
        error
      );
    }

    return null;
  }

  /**
   * Generate TTS audio buffer using Spitch API
   */
  private async generateTTSBuffer(
    text: string,
    language: "en" | "yo" | "ha" | "ig"
  ): Promise<Buffer | null> {
    if (!text || text.trim() === "") {
      logger.error(
        `‚ùå Empty text provided for Spitch TTS: language=${language}, text="${text}"`
      );
      return null;
    }

    try {
      type SpitchVoice =
        | "amina"
        | "ebuka"
        | "femi"
        | "sade"
        | "segun"
        | "funmi"
        | "aliyu"
        | "hasan"
        | "zainab"
        | "john"
        | "jude"
        | "lina"
        | "lucy"
        | "henry"
        | "kani"
        | "ngozi"
        | "amara"
        | "obinna"
        | "hana"
        | "selam"
        | "tena"
        | "tesfaye";

      const voiceMap: Record<string, SpitchVoice> = {
        en: "john",
        ha: "amina",
        ig: "amara",
        yo: "sade",
      };

      const selectedVoice = voiceMap[language] || "john";

      const response = await this.client.speech.generate({
        text,
        language,
        voice: selectedVoice,
        format: "mp3",
        model: "legacy",
      });

      const blob = await response.blob();
      const arrayBuffer = await blob.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);

      logger.info(`‚úÖ Spitch static audio generated: ${buffer.length} bytes`);
      return buffer;
    } catch (error: any) {
      logger.error(`Spitch TTS failed for ${language}:`, {
        message: error.message,
        statusCode: error.statusCode,
        code: error.code,
      });
      return null;
    }
  }

  /**
   * Get cache statistics
   */
  getCacheStats(): {
    size: number;
    keys: string[];
    cloudinaryEnabled: boolean;
  } {
    return {
      size: this.staticAudioUrls.size,
      keys: Array.from(this.staticAudioUrls.keys()),
      cloudinaryEnabled: cloudinaryService.isEnabled(),
    };
  }
}

export default new StaticAudioService();
