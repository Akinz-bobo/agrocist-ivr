import ttsService, { TTSOptions } from './ttsService';
import logger from '../utils/logger';
import cloudinaryService from './cloudinaryService';
import config from '../config';

export interface StaticAudioTexts {
  welcome: string;
  processing: string;
  error: string;
  goodbye: string;
  noRecording: string;
  wait: string;
  directRecording: string;
  followUpRecording: string;
  postAIMenu: string;
  noInputMessage: string;
  transfer: string;
  languageTimeout: string;
}

class StaticAudioService {
  private staticTexts: Record<string, StaticAudioTexts> = {
    en: {
      welcome: "Welcome to Agrocist, your trusted livestock farming partner. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo.",
      processing: "Thank you for your question. Agrocist is analyzing your concern.",
      error: "I'm sorry, I didn't understand that. Let me take you back to the main menu.",
      goodbye: "Thank you for using Agrocist. Have a great day!",
      noRecording: "I didn't hear your recording. Please try again and speak after the beep.",
      wait: "Just a moment, processing your request.",
      directRecording: "You have selected English. Please describe your livestock concern. Speak clearly after the beep and press hash when done.",
      followUpRecording: "What else can I help you with?",
      postAIMenu: "Press 1 for another question or press 0 to end the call.",
      noInputMessage: "We did not receive your selection. Let me repeat the options.",
      transfer: "Please hold while I connect you to one of our veterinary experts.",
      languageTimeout: "We did not receive your response. Let me repeat the options. Press 1 for English, 2 for Yoruba, 3 for Hausa, or 4 for Igbo."
    },
    yo: {
      welcome: "·∫∏ k√°√†b·ªçÃÄ s√≠ Agrocist, al√°b√°·π£ep·ªçÃÄ √≤we ·∫πranko t√≠ ·∫π l√® gb·∫πÃÅk·∫πÃÄl√©. ·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n G·∫πÃÄ·∫πÃÅs√¨, m√©j√¨ f√∫n Yor√πb√°, m·∫πÃÅta f√∫n Hausa, t√†b√≠ m·∫πÃÅrin f√∫n Igbo.",
      processing: "A d√∫p·∫πÃÅ f√∫n √¨b√©√®r√® y√≠n. Agrocist ≈Ñ ·π£e √¨t√∫pal·∫πÃÄ √¨·π£√≤ro y√≠n.",
      error: "M√° b√≠n√∫, k√≤ y√© mi ohun t√≠ ·∫π s·ªç. ·∫∏ j·∫πÃÅ k√≠ n gb√© y√≠n pad√† s√≠ √†t√≤j·ªç √†k·ªçÃÅk·ªçÃÅ.",
      goodbye: "A d√∫p·∫πÃÅ f√∫n lilo Agrocist. ·∫∏ n√≠ ·ªçj·ªçÃÅ t√≠ √≥ d√°ra!",
      noRecording: "Mi √≤ gb·ªçÃÅ √¨gb√≥h√πn y√≠n. ·∫∏ j·ªçÃÄw·ªçÃÅ gb√¨y√†nj√∫ l·∫πÃÅ·∫πÃÄkan si, k√≠ ·∫π s√¨ s·ªçÃÄr·ªçÃÄ l·∫πÃÅy√¨n √¨r√≥ √†l√°m·ªçÃÅ.",
      wait: "·∫∏ d√∫r√≥ d√≠·∫πÃÄ, a ≈Ñ ·π£e √¨b√©√®r√® y√≠n.",
      directRecording: "·∫∏ ti yan √àd√® Yor√πb√°. ·∫∏ s·ªç √¨·π£√≤ro ·∫πranko y√≠n kedere l·∫πÃÅy√¨n √¨r√≥ √†l√°m·ªçÃÅ (beep), k√≠ ·∫π s√¨ t·∫πÃÅ hash n√≠gb√† t√≠ ·∫π b√° par√≠.",
      followUpRecording: "K√≠ni m√¨√≠r√†n t√≠ mo l√® ·π£e f√∫n y√≠n?",
      postAIMenu: "·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n √¨b√©√®r√® m√¨√≠r√†n t√†b√≠ ·∫π t·∫πÃÅ ·ªçÃÄf√† l√°ti par√≠ √¨p√® n√°√†.",
      noInputMessage: "A k√≤ gb·ªçÃÅ √†·π£√†y√†n y√≠n. ·∫∏ j·∫πÃÅ k√≠ n t√∫n √†w·ªçn √†·π£√†y√†n n√°√† s·ªç.",
      transfer: "·∫∏ d√∫r√≥ s√≠b·∫πÃÄ k√≠ n so y√≠n m·ªçÃÅ ·ªçÃÄkan l√°ra √†w·ªçn am·ªçÃÄr√†n on√≠w√≤s√†n ·∫πranko wa.",
      languageTimeout: "A k√≤ gb·ªçÃÅ √¨d√°h√πn y√≠n. ·∫∏ j·∫πÃÅ k√≠ n t√∫n √†w·ªçn √†·π£√†y√†n n√°√† s·ªç. ·∫∏ t·∫πÃÅ ·ªçÃÄkan f√∫n G·∫πÃÄ·∫πÃÅs√¨, m√©j√¨ f√∫n Yor√πb√°, m·∫πÃÅta f√∫n Hausa, t√†b√≠ m·∫πÃÅrin f√∫n Igbo."
    },
    ha: {
      welcome: "Maraba da zuwa Agrocist, abokin gona na kiwo da za ku iya dogara da shi. Danna 1 don Turanci, 2 don Yoruba, 3 don Hausa, ko 4 don Igbo.",
      processing: "Na gode da tambayar ku. Agrocist yana nazarin damuwar ku.",
      error: "Yi hakuri, ban fahimci hakan ba. Bari in mayar da ku zuwa babban menu.",
      goodbye: "Na gode da amfani da Agrocist. Ku yi kyakkyawan rana!",
      noRecording: "Ban ji rikodin ku ba. Don Allah ku sake gwadawa kuma ku yi magana bayan sautin.",
      wait: "Don Allah ku …óan jira, muna aiwatar da bu∆ôatarku.",
      directRecording: "Kun za…ìi Hausa. Don Allah ku bayyana matsalar dabbobinku. Ku yi magana a bayyane bayan sautin (beep), sannan ku danna hash idan kun gama.",
      followUpRecording: "Me kuma zan iya taimaka muku da shi?",
      postAIMenu: "Danna 1 don wata tambaya ko danna 0 don kammala kiran.",
      noInputMessage: "Ba mu kar…ìi za…ìin ku ba. Bari in sake maimaita za…ìukan.",
      transfer: "Don Allah ku jira yayin da nake ha…óa ku da …óaya daga cikin ∆ôwararrun likitocin dabbobinmu.",
      languageTimeout: "Ba mu kar…ìi amsar ku ba. Bari in sake maimaita za…ìukan. Danna 1 don Turanci, 2 don Yoruba, 3 don Hausa, ko 4 don Igbo."
    },
    ig: {
      welcome: "Nn·ªç·ªç na Agrocist, onye enyi g·ªã n'·ªçr·ª• an·ª•man·ª• ·ªã nwere ike ·ªãdabere na ya. P·ªãa 1 maka Bekee, 2 maka Yoruba, 3 maka Hausa, ma ·ªç b·ª• 4 maka Igbo.",
      processing: "Daal·ª• maka aj·ª•j·ª• g·ªã. Agrocist na-enyocha nsogbu g·ªã.",
      error: "Ewela iwe, agh·ªçtagh·ªã m ihe ·ªã kwuru. Ka m laghachi g·ªã na menu izizi.",
      goodbye: "Daal·ª• maka iji Agrocist. Nwee ·ª•b·ªçch·ªã ·ªçma!",
      noRecording: "An·ª•gh·ªã m ndek·ªç g·ªã. Biko gbal·ªãa ·ªçz·ªç ma kwuo okwu mgbe ·ª•da ah·ª• gas·ªãr·ªã.",
      wait: "Chere ntak·ªãr·ªã, any·ªã na-edozi ihe ·ªã ch·ªçr·ªç.",
      directRecording: "·ªäh·ªçr·ªçla Igbo. Biko k·ªçwaa nsogbu an·ª•man·ª• g·ªã. Kwuo okwu n'·ª•z·ªç doro anya mgbe ·ª•da ah·ª• (beep) gas·ªãr·ªã, wee p·ªãa hash mgbe ·ªã mechara.",
      followUpRecording: "G·ªãn·ªã ·ªçz·ªç ka m nwere ike inyere g·ªã aka?",
      postAIMenu: "P·ªãa 1 maka aj·ª•j·ª• ·ªçz·ªç ma ·ªç b·ª• p·ªãa 0 iji kw·ª•s·ªã oku a.",
      noInputMessage: "Any·ªã anatabegh·ªã nh·ªçr·ªç g·ªã. Ka m kwughachi nh·ªçr·ªç nd·ªã ah·ª•.",
      transfer: "Biko chere ka m jik·ªç·ªç g·ªã na otu n'ime nd·ªã ·ªçkachamara veterinary any·ªã.",
      languageTimeout: "Any·ªã anatabegh·ªã az·ªãza g·ªã. Ka m kwughachi nh·ªçr·ªç nd·ªã ah·ª•. P·ªãa 1 maka Bekee, 2 maka Yoruba, 3 maka Hausa, ma ·ªç b·ª• 4 maka Igbo."
    }
  };

  private staticAudioUrls: Map<string, string> = new Map();

  /**
   * Pre-generate all static audio files at startup
   */
  async preGenerateStaticAudio(): Promise<void> {
    logger.info('üéµ Starting static audio pre-generation...');
    const startTime = Date.now();
    let successCount = 0;
    let failedCount = 0;

    // Quick DSN API health check
    const ttsService = (await import('./ttsService')).default;
    const token = await ttsService.authenticateDSN();
    
    if (!token) {
      logger.error('‚ùå DSN API unavailable - static audio generation failed');
      logger.info('üéµ Static audio pre-generation completed in 0ms');
      logger.info(`‚úÖ Success: 0, ‚ùå Failed: 0, Total: 0 (failed due to DSN API unavailability)`);
      return;
    }

    const languages: Array<'en' | 'yo' | 'ha' | 'ig'> = ['en', 'yo', 'ha', 'ig'];
    
    // Build list of all files to process
    const allFiles: Array<{language: string, key: string, text: string}> = [];
    
    for (const language of languages) {
      const texts = this.staticTexts[language];
      
      if (!texts) {
        logger.error(`‚ùå No texts found for language: ${language}`);
        continue;
      }
      
      // Add each file to the processing queue
      for (const [key, text] of Object.entries(texts)) {
        allFiles.push({language, key, text: text as string});
      }
    }
    
    logger.info(`üöÄ Processing ${allFiles.length} static audio files sequentially...`);
    
    // Process files one by one to avoid overwhelming TTS API
    const results: PromiseSettledResult<void>[] = [];
    
    for (let i = 0; i < allFiles.length; i++) {
      const file = allFiles[i];
      if (!file) continue;
      
      logger.info(`üìÑ Processing file ${i + 1}/${allFiles.length}...`);
      
      try {
        await this.processStaticAudio(file.language, file.key, file.text);
        results.push({status: 'fulfilled', value: undefined});
      } catch (error) {
        results.push({status: 'rejected', reason: error});
      }
      
      // Add a delay between each file to prevent API rate limiting
      if (i + 1 < allFiles.length) {
        await new Promise(resolve => setTimeout(resolve, 2000)); // 2 second delay between files
      }
    }
    
    // Count results
    results.forEach((result, index) => {
      if (result.status === 'fulfilled') {
        successCount++;
      } else {
        failedCount++;
        logger.error(`‚ùå Task ${index} failed:`, result.reason);
      }
    });

    const totalTime = Date.now() - startTime;
    logger.info(`üéµ Static audio pre-generation completed in ${totalTime}ms`);
    logger.info(`‚úÖ Success: ${successCount}, ‚ùå Failed: ${failedCount}, Total: ${successCount + failedCount}`);
  }

  /**
   * Get pre-generated static audio URL
   */
  getStaticAudioUrl(language: 'en' | 'yo' | 'ha' | 'ig', textKey: keyof StaticAudioTexts): string | null {
    const cacheKey = `${language}_${textKey}`;
    return this.staticAudioUrls.get(cacheKey) || null;
  }

  /**
   * Get static text for fallback
   */
  getStaticText(language: 'en' | 'yo' | 'ha' | 'ig', textKey: keyof StaticAudioTexts): string {
    const languageTexts = this.staticTexts[language];
    const englishTexts = this.staticTexts.en;
    
    return languageTexts?.[textKey] || englishTexts?.[textKey] || '';
  }

  /**
   * Process a single static audio file (check existence + generate if needed)
   */
  private async processStaticAudio(language: string, key: string, text: string): Promise<void> {
    const cacheKey = `${language}_${key}`;
    let finalUrl: string | null = null;
    
    // FASTEST PATH: Check if we already have this file URL cached in memory
    if (this.staticAudioUrls.has(cacheKey)) {
      finalUrl = this.staticAudioUrls.get(cacheKey)!;
      logger.info(`‚ö° SKIPPED: Using cached static audio URL: ${cacheKey}`);
      return;
    }
    
    // FAST PATH: Check if file exists on Cloudinary (only if not in memory cache)
    if (cloudinaryService.isEnabled()) {
      const basePublicId = cloudinaryService.generatePublicId(text, language, 'static', key);
      const staticPublicId = `${config.cloudinary.folder}/static/${basePublicId}`;
      
      try {
        logger.info(`üîç Checking for existing file on Cloudinary: ${staticPublicId}`);
        const existsOnCloudinary = await cloudinaryService.fileExists(staticPublicId);
        
        if (existsOnCloudinary) {
          // File already exists, use the existing URL (FAST PATH)
          const existingCloudinaryUrl = cloudinaryService.getOptimizedUrl(staticPublicId);
          if (existingCloudinaryUrl) {
            finalUrl = existingCloudinaryUrl;
            logger.info(`‚ôªÔ∏è SKIPPED: Using existing static Cloudinary file: ${cacheKey} (${staticPublicId})`);
          }
        } else {
          // File doesn't exist, generate and upload it (SLOW PATH)
          logger.info(`üì§ Generating new static audio: ${cacheKey} (will upload as ${staticPublicId})`);
          finalUrl = await this.uploadStaticToCloudinary(text, language, key);
          if (finalUrl) {
            logger.info(`‚úÖ Uploaded new static audio to Cloudinary: ${cacheKey}`);
          }
        }
      } catch (error) {
        // If Cloudinary API is having issues, try to get URL directly first
        logger.warn(`Cloudinary API error for ${cacheKey}, trying direct URL:`, error);
        const directUrl = cloudinaryService.getOptimizedUrl(staticPublicId);
        if (directUrl) {
          finalUrl = directUrl;
          logger.info(`‚ôªÔ∏è Using direct Cloudinary URL despite API error: ${cacheKey}`);
        } else {
          // Last resort: generate new file
          finalUrl = await this.uploadStaticToCloudinary(text, language, key);
          if (finalUrl) {
            logger.info(`‚úÖ Generated static audio despite API issues: ${cacheKey}`);
          }
        }
      }
    } else {
      // Cloudinary disabled, generate anyway
      finalUrl = await this.uploadStaticToCloudinary(text, language, key);
    }
    
    if (finalUrl) {
      this.staticAudioUrls.set(cacheKey, finalUrl);
      logger.debug(`‚úÖ Generated ${cacheKey}: ${text.substring(0, 50)}...`);
    } else {
      logger.error(`‚ùå Failed to generate static audio for ${cacheKey} - static file not available`);
    }
  }

  /**
   * Upload static audio file to Cloudinary directly from TTS buffer
   */
  async uploadStaticToCloudinary(
    text: string, 
    language: string, 
    textKey: string
  ): Promise<string | null> {
    try {
      // Use centralized static publicId generation for consistency
      const publicId = cloudinaryService.generatePublicId(text, language, 'static', textKey);

      console.log(`Uploading static audio to Cloudinary with publicId: ${publicId}`);
      
      // Generate TTS audio buffer directly (don't save to disk)
      const audioBuffer = await this.generateTTSBuffer(text, language as 'en' | 'yo' | 'ha' | 'ig');
      if (!audioBuffer) {
        logger.warn(`Failed to generate TTS buffer for static audio: ${language}_${textKey}`);
        return null;
      }
      
      const cloudinaryResult = await cloudinaryService.uploadAudioBuffer(audioBuffer, {
        publicId,
        folder: `${config.cloudinary.folder}/static`
      });
      
      if (cloudinaryResult) {
        logger.info(`‚úÖ Successfully uploaded static audio to Cloudinary:`);
        logger.info(`   üìÑ File: ${language}_${textKey}`);
        logger.info(`   üîó PublicId: ${cloudinaryResult.publicId}`);
        logger.info(`   üåê URL: ${cloudinaryResult.secureUrl}`);
        return cloudinaryResult.secureUrl;
      }
    } catch (error) {
      logger.warn(`Failed to upload static audio to Cloudinary: ${language}_${textKey}`, error);
    }
    
    return null;
  }

  /**
   * Generate TTS audio buffer without saving to disk
   */
  private async generateTTSBuffer(text: string, language: 'en' | 'yo' | 'ha' | 'ig'): Promise<Buffer | null> {
    // Debug: Log the exact text being passed to DSN API
    logger.debug(`üîç DSN TTS Request - Language: ${language}, Text: "${text}" (length: ${text?.length || 0})`);
    
    if (!text || text.trim() === '') {
      logger.error(`‚ùå Empty text provided for DSN TTS: language=${language}, text="${text}"`);
      return null;
    }
    
    try {
      const axios = require('axios');
      const FormData = require('form-data');
      
      // Reuse TTS authentication and generation logic
      const ttsService = (await import('./ttsService')).default;
      const token = await ttsService.authenticateDSN();
      
      if (!token) {
        logger.warn('DSN API authentication failed');
        return null;
      }

      // Voice configurations
      const voiceConfigs: Record<string, any> = {
        en: { voiceId: 'lucy', language: 'en' },
        yo: { voiceId: 'sade', language: 'yo' },
        ha: { voiceId: 'zainab', language: 'ha' },
        ig: { voiceId: 'amara', language: 'ig' }
      };

      const voiceConfig = voiceConfigs[language];
      if (!voiceConfig) {
        logger.warn(`No voice configuration found for language: ${language}`);
        return null;
      }

      // Create form data for the request
      const formData = new FormData();
      formData.append('text', text);
      formData.append('language', voiceConfig.language);
      formData.append('voice', voiceConfig.voiceId);
      formData.append('format', 'mp3');
      formData.append('quality', 'medium');
      formData.append('encoding', 'mp3_64');

      // Make request to DSN TTS API with form-data
      const response = await axios({
        method: 'POST',
        url: `${config.dsn.baseUrl}/api/v1/ai/spitch/text-to-speech`,
        data: formData,
        headers: {
          ...formData.getHeaders(),
          'Authorization': `Bearer ${token}`
        },
        responseType: 'arraybuffer',
        timeout: 30000
      });
      
      return Buffer.from(response.data);
    } catch (error: any) {
      // Handle common timeout and connection errors concisely
      if (error.code === 'ECONNABORTED' || error.code === 'ETIMEDOUT') {
        logger.warn(`DSN API timeout for ${language} audio generation`);
      } else if (error.response?.status === 504) {
        logger.warn(`DSN API gateway timeout (504) for ${language} audio`);
      } else if (error.response?.status >= 500) {
        logger.warn(`DSN API server error (${error.response.status}) for ${language} audio`);
      } else {
        const errorDetails = {
          status: error.response?.status,
          statusText: error.response?.statusText,
          data: error.response?.data,
          message: error.message
        };
        logger.warn(`DSN TTS failed for ${language}:`, errorDetails);
      }
      return null;
    }
  }

  /**
   * Get cache statistics
   */
  getCacheStats(): { 
    size: number; 
    keys: string[];
    cloudinaryEnabled: boolean;
  } {
    return {
      size: this.staticAudioUrls.size,
      keys: Array.from(this.staticAudioUrls.keys()),
      cloudinaryEnabled: cloudinaryService.isEnabled()
    };
  }
}

export default new StaticAudioService();